{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRcU55v94GOs"
   },
   "source": [
    "# **K-Means using Spark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Unen5veB9bOP"
   },
   "source": [
    "# **Task:** Perform a Kmeans clustering for the given Dataset\n",
    "    \n",
    "# **Dataset:** Breast cancer Dataset (From the Sklearn Library)\n",
    "\n",
    "## **Date:** 20|10|22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbiL2g389Xkb"
   },
   "source": [
    "### **Setup for PySpark API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHAaFZSKZ_uR"
   },
   "source": [
    "**Step 1:**  We install PySpark which is the Python API for Apache Spark which is an open source,distributed computing framework and set of libaries for real-time,large scale data processing.It is written in Python to run a Python application using Apache Spark capabilities.The Python driver program communicates with a local JVM(Java Virtual Machine) running Spark via Py4J. Which is a Java library that is integrated within PySpark and allows python to dynamically interface with JVM objects.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NytKsK6T3z8h",
    "outputId": "2e7f0c38-a760-4b84-f5cf-104596710616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.3 MB 45 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 37.1 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=bf5d81d2e253bc4722f1024d5b6fc2431e6fbb443ecd5e5d479be338849f53d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl1t3fzmcY_d"
   },
   "source": [
    "**Step 2: PyDrive** is installed, as it simplifies many common Google Drive API tasks. It has the following features:\n",
    "\n",
    "1. Simplifies OAuth2.0 into just few lines with flexible settings.\n",
    "\n",
    "2. Wraps Google Drive API into classes of each resource to make your program more object-oriented.\n",
    "\n",
    "3. Helps common operations else than API calls, such as content fetching and pagination control.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H8LhEby74Q4p"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y05RBqbEnmCr"
   },
   "source": [
    "**Step 3:**  \n",
    "Since PySpark uses **Java**, we need to have Java while using PySpark. We use Open JDK(or Open Java Development Kit) which is a open source and free implementation of Java Platform.\n",
    "\n",
    "**Extra info for understanding:**\n",
    "Java Development Kit (in short JDK) is Kit which provides the environment to Develop and execute(run ) the Java program. JDK contains Java Run Environment (JRE) and Java Virtual Machine(JVM)\n",
    "\n",
    "Here, **'8'** refers to the version and **headless** are software  capable of working on a device without a graphical user interface. Such software receives inputs and provides output through other interfaces like network or serial port and is common on servers and embedded devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4Nm3knL4WFk",
    "outputId": "cfa37289-5aef-4b38-aa43-0a03c7a74ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk-8-jdk-headless is already the newest version (8u342-b07-0ubuntu1~18.04).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt install openjdk-8-jdk-headless -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk9GRBf7cT5I"
   },
   "source": [
    "**Step 4:**\n",
    "\n",
    "We import the **os** module which allows the user to interact with the Operating system that he/she is currently working on and also provides with a portable way to use the operating system dependent functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m9Epcr3aS-pp"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oav-s3EWTJO-"
   },
   "source": [
    "**Step 5:** We need to set environment variables for the JDK \n",
    "\n",
    "JAVA_HOME is the name of an environment variable on the operating system that points to the installation directory of JDK (Java Development Kit) or JRE (Java Runtime Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cBC6wm9k4sYr"
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu7AWy1oTlGx"
   },
   "source": [
    "**Step 6:** Importing the necessary Python Libraries for Data Analysis and Visualization. \n",
    "\n",
    "Additionally we import the following:\n",
    "\n",
    "1. PySpark SQL is a module in Spark which integrates relational processing with Spark's functional programming API.Thus, we can extract the data by using an SQL query language.\n",
    "2. pyspark.sql.types - It represents a list of available data types.\n",
    "3. pyspark.sql.functions - It represents a list of built-in functions available for DataFrame.\n",
    "4. SparkContext is an entry point to the PySpark functionality that is used to communicate with the cluster and to create an RDD, accumulator, and broadcast variables.The Spark driver program creates and uses SparkContext to connect to the cluster manager to submit PySpark jobs, and know what resource manager (YARN, Mesos, or Standalone) to communicate to. It is the heart of the PySpark application.\n",
    "5. SparkConf - To run a Spark application on the local/cluster, you need to set a few configurations and parameters, this is what SparkConf helps with. It provides configurations to run a Spark application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AAd-qTRc5nbe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0iaAwxlbFl1"
   },
   "source": [
    "**Step 7:** We will create a **SparkConf** object with SparkConf(), which will load the values from spark.* Java system properties as well. Now we can set different parameters using the SparkConf object and their parameters will take priority over the system properties. And using the set attribute of PysparkConfig we set the configuration properties.\n",
    "\n",
    "Then we create a **spark Context** object and also use the **SparkSession.builder.getOrCreate()** method which first checks whether there is a valid global default SparkSession, and if yes, return that one. If no valid global default SparkSession exists, the method creates a new SparkSession and assigns the newly created SparkSession as the global default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EmdQQ9iD64PQ"
   },
   "outputs": [],
   "source": [
    "# create the session \n",
    "conf = SparkConf().set(\"spark.ui.port\",\"4050\")\n",
    "\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIcdS-8gkmyV"
   },
   "source": [
    "**Step 8:** Now we can easily check the current version and get the link of the web interface. In the Spark UI, we can monitor the progress of the job and debug the performance bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "_pzaS0tE74hW",
    "outputId": "acce51b0-33b1-4b3f-9231-8eb18d5bee04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a485d6f1c0bd:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe5f36a1690>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdma3jytk7lA"
   },
   "source": [
    "**Step 9:** Now we use the wget method to retrieve the .zip file. \n",
    "\n",
    "**Extra info:**\n",
    "GNU Wget is a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS, the most widely used Internet protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXkA91IV9Nog",
    "outputId": "888002c9-ea81-43b9-a57b-10f603008809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-20 17:50:55--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 52.202.168.65, 18.205.222.128, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13832437 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.19M  6.49MB/s    in 2.0s    \n",
      "\n",
      "2022-10-20 17:50:58 (6.49 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVApnNeP7p7T"
   },
   "source": [
    "**Step 10:** Now, we use unzip command to extract the data from the zipped file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6zYHbrRhErW",
    "outputId": "4562778e-eaf1-4dc8-c189-661aa9d5adc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcQ7ihrQ71Ei"
   },
   "source": [
    "**Step 11:** We have configured the Spark UI and started a Spark session in the previous cells. Here, this command is used to create a Colab application UI on the Apache Spark website under the Jobs tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "w6QKXjNWhHyU"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 4050 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bx6uVDBM73xD"
   },
   "source": [
    "**Step 12:** The above code creates and gives a public URL for the UI page to view the Spark UI. Now we can view the jobs and their stages at the link created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8tF0eJNhL-U",
    "outputId": "34a310a4-a32e-44d7-a755-daceac5eb0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ba25-34-80-143-255.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_pxei_j90vi"
   },
   "source": [
    "## **Data Processing**\n",
    "\n",
    "Steps involved in Data Processing are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kNh28cbdayj"
   },
   "source": [
    "**Step 1:** Importing the Breast cancer Dataset from the Scikit Learn Library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "N8T7m94i90Fh"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1oiGAbAlbrO"
   },
   "source": [
    "**Step 2:**\n",
    "\n",
    "A) Converting the data to a pandas DataFrame\n",
    "\n",
    "B) Then converting this data frame to Spark Data Frame using createDataFrame method.\n",
    "\n",
    "C) Now data.schema contains three parts which are: **name,StringType,nullable (Which is set to true by default).**\n",
    "Now we create a function **'set_df_columns_nullable'** which converts the nullable into **False**, Thus, no** none values** are allowed in each of the columns. Next our function first converts the dataframe to a RDD (Using .rdd) and then returns a DataFrame  \n",
    "\n",
    "D) Now using the method .withcolumn we add another column (called features) to our data frame in which each row contains a list consisting of values of the other columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "In5YWJpf-D3q",
    "outputId": "a5a9e2af-a8bb-404c-e003-c04166b4492c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+--------------------+\n",
      "|mean radius|mean texture|mean perimeter|mean area|mean smoothness|mean compactness|mean concavity|mean concave points|mean symmetry|mean fractal dimension|radius error|texture error|perimeter error|area error|smoothness error|compactness error|concavity error|concave points error|symmetry error|fractal dimension error|worst radius|worst texture|worst perimeter|worst area|worst smoothness|worst compactness|worst concavity|worst concave points|worst symmetry|worst fractal dimension|            features|\n",
      "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+--------------------+\n",
      "|      17.99|       10.38|         122.8|   1001.0|         0.1184|          0.2776|        0.3001|             0.1471|       0.2419|               0.07871|       1.095|       0.9053|          8.589|     153.4|        0.006399|          0.04904|        0.05373|             0.01587|       0.03003|               0.006193|       25.38|        17.33|          184.6|    2019.0|          0.1622|           0.6656|         0.7119|              0.2654|        0.4601|                 0.1189|[17.99, 10.38, 12...|\n",
      "|      20.57|       17.77|         132.9|   1326.0|        0.08474|         0.07864|        0.0869|            0.07017|       0.1812|               0.05667|      0.5435|       0.7339|          3.398|     74.08|        0.005225|          0.01308|         0.0186|              0.0134|       0.01389|               0.003532|       24.99|        23.41|          158.8|    1956.0|          0.1238|           0.1866|         0.2416|               0.186|         0.275|                0.08902|[20.57, 17.77, 13...|\n",
      "|      19.69|       21.25|         130.0|   1203.0|         0.1096|          0.1599|        0.1974|             0.1279|       0.2069|               0.05999|      0.7456|       0.7869|          4.585|     94.03|         0.00615|          0.04006|        0.03832|             0.02058|        0.0225|               0.004571|       23.57|        25.53|          152.5|    1709.0|          0.1444|           0.4245|         0.4504|               0.243|        0.3613|                0.08758|[19.69, 21.25, 13...|\n",
      "|      11.42|       20.38|         77.58|    386.1|         0.1425|          0.2839|        0.2414|             0.1052|       0.2597|               0.09744|      0.4956|        1.156|          3.445|     27.23|         0.00911|          0.07458|        0.05661|             0.01867|       0.05963|               0.009208|       14.91|         26.5|          98.87|     567.7|          0.2098|           0.8663|         0.6869|              0.2575|        0.6638|                  0.173|[11.42, 20.38, 77...|\n",
      "|      20.29|       14.34|         135.1|   1297.0|         0.1003|          0.1328|         0.198|             0.1043|       0.1809|               0.05883|      0.7572|       0.7813|          5.438|     94.44|         0.01149|          0.02461|        0.05688|             0.01885|       0.01756|               0.005115|       22.54|        16.67|          152.2|    1575.0|          0.1374|            0.205|            0.4|              0.1625|        0.2364|                0.07678|[20.29, 14.34, 13...|\n",
      "|      12.45|        15.7|         82.57|    477.1|         0.1278|            0.17|        0.1578|            0.08089|       0.2087|               0.07613|      0.3345|       0.8902|          2.217|     27.19|         0.00751|          0.03345|        0.03672|             0.01137|       0.02165|               0.005082|       15.47|        23.75|          103.4|     741.6|          0.1791|           0.5249|         0.5355|              0.1741|        0.3985|                 0.1244|[12.45, 15.7, 82....|\n",
      "|      18.25|       19.98|         119.6|   1040.0|        0.09463|           0.109|        0.1127|              0.074|       0.1794|               0.05742|      0.4467|       0.7732|           3.18|     53.91|        0.004314|          0.01382|        0.02254|             0.01039|       0.01369|               0.002179|       22.88|        27.66|          153.2|    1606.0|          0.1442|           0.2576|         0.3784|              0.1932|        0.3063|                0.08368|[18.25, 19.98, 11...|\n",
      "|      13.71|       20.83|          90.2|    577.9|         0.1189|          0.1645|       0.09366|            0.05985|       0.2196|               0.07451|      0.5835|        1.377|          3.856|     50.96|        0.008805|          0.03029|        0.02488|             0.01448|       0.01486|               0.005412|       17.06|        28.14|          110.6|     897.0|          0.1654|           0.3682|         0.2678|              0.1556|        0.3196|                 0.1151|[13.71, 20.83, 90...|\n",
      "|       13.0|       21.82|          87.5|    519.8|         0.1273|          0.1932|        0.1859|            0.09353|        0.235|               0.07389|      0.3063|        1.002|          2.406|     24.32|        0.005731|          0.03502|        0.03553|             0.01226|       0.02143|               0.003749|       15.49|        30.73|          106.2|     739.3|          0.1703|           0.5401|          0.539|               0.206|        0.4378|                 0.1072|[13.0, 21.82, 87....|\n",
      "|      12.46|       24.04|         83.97|    475.9|         0.1186|          0.2396|        0.2273|            0.08543|        0.203|               0.08243|      0.2976|        1.599|          2.039|     23.94|        0.007149|          0.07217|        0.07743|             0.01432|       0.01789|                0.01008|       15.09|        40.68|          97.65|     711.4|          0.1853|            1.058|          1.105|               0.221|        0.4366|                 0.2075|[12.46, 24.04, 83...|\n",
      "|      16.02|       23.24|         102.7|    797.8|        0.08206|         0.06669|       0.03299|            0.03323|       0.1528|               0.05697|      0.3795|        1.187|          2.466|     40.51|        0.004029|         0.009269|        0.01101|            0.007591|        0.0146|               0.003042|       19.19|        33.88|          123.8|    1150.0|          0.1181|           0.1551|         0.1459|             0.09975|        0.2948|                0.08452|[16.02, 23.24, 10...|\n",
      "|      15.78|       17.89|         103.6|    781.0|         0.0971|          0.1292|       0.09954|            0.06606|       0.1842|               0.06082|      0.5058|       0.9849|          3.564|     54.16|        0.005771|          0.04061|        0.02791|             0.01282|       0.02008|               0.004144|       20.42|        27.28|          136.5|    1299.0|          0.1396|           0.5609|         0.3965|               0.181|        0.3792|                 0.1048|[15.78, 17.89, 10...|\n",
      "|      19.17|        24.8|         132.4|   1123.0|         0.0974|          0.2458|        0.2065|             0.1118|       0.2397|                 0.078|      0.9555|        3.568|          11.07|     116.2|        0.003139|          0.08297|         0.0889|              0.0409|       0.04484|                0.01284|       20.96|        29.94|          151.7|    1332.0|          0.1037|           0.3903|         0.3639|              0.1767|        0.3176|                 0.1023|[19.17, 24.8, 132...|\n",
      "|      15.85|       23.95|         103.7|    782.7|        0.08401|          0.1002|       0.09938|            0.05364|       0.1847|               0.05338|      0.4033|        1.078|          2.903|     36.58|        0.009769|          0.03126|        0.05051|             0.01992|       0.02981|               0.003002|       16.84|        27.66|          112.0|     876.5|          0.1131|           0.1924|         0.2322|              0.1119|        0.2809|                0.06287|[15.85, 23.95, 10...|\n",
      "|      13.73|       22.61|          93.6|    578.3|         0.1131|          0.2293|        0.2128|            0.08025|       0.2069|               0.07682|      0.2121|        1.169|          2.061|     19.21|        0.006429|          0.05936|        0.05501|             0.01628|       0.01961|               0.008093|       15.03|        32.01|          108.8|     697.7|          0.1651|           0.7725|         0.6943|              0.2208|        0.3596|                 0.1431|[13.73, 22.61, 93...|\n",
      "|      14.54|       27.54|         96.73|    658.8|         0.1139|          0.1595|        0.1639|            0.07364|       0.2303|               0.07077|        0.37|        1.033|          2.879|     32.55|        0.005607|           0.0424|        0.04741|              0.0109|       0.01857|               0.005466|       17.46|        37.13|          124.1|     943.2|          0.1678|           0.6577|         0.7026|              0.1712|        0.4218|                 0.1341|[14.54, 27.54, 96...|\n",
      "|      14.68|       20.13|         94.74|    684.5|        0.09867|           0.072|       0.07395|            0.05259|       0.1586|               0.05922|      0.4727|         1.24|          3.195|      45.4|        0.005718|          0.01162|        0.01998|             0.01109|        0.0141|               0.002085|       19.07|        30.88|          123.4|    1138.0|          0.1464|           0.1871|         0.2914|              0.1609|        0.3029|                0.08216|[14.68, 20.13, 94...|\n",
      "|      16.13|       20.68|         108.1|    798.8|          0.117|          0.2022|        0.1722|             0.1028|       0.2164|               0.07356|      0.5692|        1.073|          3.854|     54.18|        0.007026|          0.02501|        0.03188|             0.01297|       0.01689|               0.004142|       20.96|        31.48|          136.8|    1315.0|          0.1789|           0.4233|         0.4784|              0.2073|        0.3706|                 0.1142|[16.13, 20.68, 10...|\n",
      "|      19.81|       22.15|         130.0|   1260.0|        0.09831|          0.1027|        0.1479|            0.09498|       0.1582|               0.05395|      0.7582|        1.017|          5.865|     112.4|        0.006494|          0.01893|        0.03391|             0.01521|       0.01356|               0.001997|       27.32|        30.88|          186.8|    2398.0|          0.1512|            0.315|         0.5372|              0.2388|        0.2768|                0.07615|[19.81, 22.15, 13...|\n",
      "|      13.54|       14.36|         87.46|    566.3|        0.09779|         0.08129|       0.06664|            0.04781|       0.1885|               0.05766|      0.2699|       0.7886|          2.058|     23.56|        0.008462|           0.0146|        0.02387|             0.01315|        0.0198|                 0.0023|       15.11|        19.26|           99.7|     711.2|           0.144|           0.1773|          0.239|              0.1288|        0.2977|                0.07259|[13.54, 14.36, 87...|\n",
      "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd_df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "df = spark.createDataFrame(pd_df)\n",
    "\n",
    "def set_df_columns_nullable(spark, df, column_list, nullable=False):\n",
    "    for struct_field in df.schema:\n",
    "        if struct_field.name in column_list:\n",
    "            struct_field.nullable = nullable\n",
    "    df_mod = spark.createDataFrame(df.rdd, df.schema)\n",
    "    return df_mod\n",
    "df = set_df_columns_nullable(spark, df, df.columns)\n",
    "df = df.withColumn('features', array(df.columns))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjXmGDbhwdl_"
   },
   "source": [
    "**Step 3:** Here, we first convert the data frame into rdd then use **map** which is an RDD transformation that is used to apply the transformation function (lambda) on every element of RDD/DataFrame and returns a new RDD. And thus it converts each row in the **'feature'** column from a **list** to **dense Vectors** data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-GACk5hwSkP",
    "outputId": "11ec7d56-22b8-4d08-c734-ac0dee148fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mean radius: double (nullable = false)\n",
      " |-- mean texture: double (nullable = false)\n",
      " |-- mean perimeter: double (nullable = false)\n",
      " |-- mean area: double (nullable = false)\n",
      " |-- mean smoothness: double (nullable = false)\n",
      " |-- mean compactness: double (nullable = false)\n",
      " |-- mean concavity: double (nullable = false)\n",
      " |-- mean concave points: double (nullable = false)\n",
      " |-- mean symmetry: double (nullable = false)\n",
      " |-- mean fractal dimension: double (nullable = false)\n",
      " |-- radius error: double (nullable = false)\n",
      " |-- texture error: double (nullable = false)\n",
      " |-- perimeter error: double (nullable = false)\n",
      " |-- area error: double (nullable = false)\n",
      " |-- smoothness error: double (nullable = false)\n",
      " |-- compactness error: double (nullable = false)\n",
      " |-- concavity error: double (nullable = false)\n",
      " |-- concave points error: double (nullable = false)\n",
      " |-- symmetry error: double (nullable = false)\n",
      " |-- fractal dimension error: double (nullable = false)\n",
      " |-- worst radius: double (nullable = false)\n",
      " |-- worst texture: double (nullable = false)\n",
      " |-- worst perimeter: double (nullable = false)\n",
      " |-- worst area: double (nullable = false)\n",
      " |-- worst smoothness: double (nullable = false)\n",
      " |-- worst compactness: double (nullable = false)\n",
      " |-- worst concavity: double (nullable = false)\n",
      " |-- worst concave points: double (nullable = false)\n",
      " |-- worst symmetry: double (nullable = false)\n",
      " |-- worst fractal dimension: double (nullable = false)\n",
      " |-- features: array (nullable = false)\n",
      " |    |-- element: double (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "vectors = df.rdd.map(lambda row: Vectors.dense(row.features))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgfaEyZU2Pd8"
   },
   "source": [
    "**Step 4:** Finally we  create a new data frame called features, also a series for our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQZxlVol_Ada",
    "outputId": "8f8adc22-5e6d-420d-8c03-ed9a10428a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[17.99,10.38,122....|\n",
      "|[20.57,17.77,132....|\n",
      "|[19.69,21.25,130....|\n",
      "|[11.42,20.38,77.5...|\n",
      "|[20.29,14.34,135....|\n",
      "|[12.45,15.7,82.57...|\n",
      "|[18.25,19.98,119....|\n",
      "|[13.71,20.83,90.2...|\n",
      "|[13.0,21.82,87.5,...|\n",
      "|[12.46,24.04,83.9...|\n",
      "|[16.02,23.24,102....|\n",
      "|[15.78,17.89,103....|\n",
      "|[19.17,24.8,132.4...|\n",
      "|[15.85,23.95,103....|\n",
      "|[13.73,22.61,93.6...|\n",
      "|[14.54,27.54,96.7...|\n",
      "|[14.68,20.13,94.7...|\n",
      "|[16.13,20.68,108....|\n",
      "|[19.81,22.15,130....|\n",
      "|[13.54,14.36,87.4...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = spark.createDataFrame(vectors.map(Row),[\"features\"])\n",
    "features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhe_a56i4kkD"
   },
   "outputs": [],
   "source": [
    "#Target Variable\n",
    "labels = pd.Series(breast_cancer.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HiTCkPS5QM1"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "Steps involved are:\n",
    "\n",
    "**Step 1:** Importing the required libraries, these are pySpark specific libraries for using Kmeans algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "hoQC35A6CMqC"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVPxlFm26RXk"
   },
   "source": [
    "**Step 2:** Using two clusters and using setSeed method to 1, so that we get the same set of clusters evertime we run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Z41YBOoI-ZXG"
   },
   "outputs": [],
   "source": [
    "# trains a K-means model\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrU7h3-W6sxK"
   },
   "source": [
    "**Step 3:** Now, predicting the cluster observations using the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "374JuJxz5uL0"
   },
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "prediction = model.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn_r1ij863Ma"
   },
   "source": [
    "**Step 4:** Finally, evaluating our prediction using the silhoutte coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "vJwsojs_5uUC"
   },
   "outputs": [],
   "source": [
    "# Evaluate clustering by computing Silhoutte Score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ToP9lOYn5ye0",
    "outputId": "5d14d6ab-2a67-40ec-dc03-4b8cc78f1130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhoutte with squared eculidean distance = 0.8342904262826145\n"
     ]
    }
   ],
   "source": [
    "silhoutte = evaluator.evaluate(prediction)\n",
    "print('Silhoutte with squared eculidean distance = '+ str(silhoutte))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
