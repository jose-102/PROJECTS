{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nse-pY9Qf55J"
      },
      "source": [
        "\n",
        "**Combating Hate Speech Using NLP and machine Learning**\n",
        "\n",
        "\n",
        "\n",
        "**Objective:** Using NLP and ML, create a model to identify hate speech in Twitter.\n",
        "\n",
        "\n",
        "\n",
        "**Problem Statement:** Twitter is one of the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being uesd as a medium to spread hate.\n",
        "\n",
        "\n",
        "\n",
        "You are a data scientist at Twitter, and you will help Twitter in identifying the tweets with hate speech and removing them from the paltform. You will use NLP techniques, Perform specific cleanup for tweets data, and make a robust model.\n",
        "\n",
        "\n",
        "\n",
        "**Domain:** Social media \n",
        "\n",
        "\n",
        "\n",
        "**Analysis to be done:**  Clean up tweets and build a classification model by using NLP techniques, cleanup specific for tweets data, regularization and hyperparameter tuning using stratified K-fold and cross validation to get the best model.\n",
        "\n",
        "\n",
        "\n",
        "**Content:**\n",
        "\n",
        "\n",
        "\n",
        "**Id:** identifer number of the tweet\n",
        "\n",
        "\n",
        "\n",
        "**Label:** 0(non-hate)/ 1(hate)\n",
        "\n",
        "\n",
        "\n",
        "**Tweet**: the text in the tweet\n",
        "\n",
        "**Date:** 15-11-22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckydRDD26Krs"
      },
      "source": [
        "# **Importing the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef-6MuiAvW_5",
        "outputId": "1abaad8d-7c8b-4638-e21c-ceb68ea96138"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd   # To work with data frames\n",
        "import numpy as np    # advanced math library\n",
        "import os, re         # Helps in working with file paths \n",
        "                      # Library to work with regular expression\n",
        "\n",
        "import nltk                              # It is a suite of libraries and programs for symbolic and statistical natural language processing for English.\n",
        "from nltk.tokenize import TweetTokenizer # Tokenize using tweet Tokenize from NLTK\n",
        "nltk.download('stopwords')               # This is used to download all lthe stop words in english language\n",
        "from nltk.corpus import stopwords        # Importing all the stopwords\n",
        "from string import punctuation           # To get all the punctuations used in english language.\n",
        "\n",
        "# For lemmitization\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from collections import Counter          # From the collection module we are importing the class Counter \n",
        "\n",
        "from sklearn.model_selection import train_test_split # For dividing the data into train and test\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression # importing the required models \n",
        "from sklearn.ensemble import RandomForestClassifier # importing the random Forest model\n",
        "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix,matthews_corrcoef # For importing all the required metrics\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold # Using Grid Search to find the optimum parameters\n",
        "                                                                  # LIbrary for using stratified K Fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfEulpsq7q1C"
      },
      "source": [
        "# **Importing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "I_rpTvzWo1Ux",
        "outputId": "083cf4a5-eadb-4517-e3b2-3ba7f7c210c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87d8decb-26d2-4482-acd8-0b32d01913d9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-87d8decb-26d2-4482-acd8-0b32d01913d9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Tweets_USA.csv to Tweets_USA (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-JZlE5KwEFL"
      },
      "outputs": [],
      "source": [
        "inp_tweets0 = pd.read_csv(\"Tweets_USA.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ls2xPiN7zbi"
      },
      "source": [
        "# **Exploring the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OgGeB7PIwMnn",
        "outputId": "5c7f144b-8ddc-4020-e6bb-a28c1fde0064"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0e4f8ebd-39d4-4a39-9763-9c46728004f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e4f8ebd-39d4-4a39-9763-9c46728004f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e4f8ebd-39d4-4a39-9763-9c46728004f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e4f8ebd-39d4-4a39-9763-9c46728004f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation\n",
              "5   6      0  [2/2] huge fan fare and big talking before the...\n",
              "6   7      0   @user camping tomorrow @user @user @user @use...\n",
              "7   8      0  the next school year is the year for exams.ð...\n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Observing the first 10 observations\n",
        "# Now there are three columns in the data, \n",
        "# first is the ids, second being the labels hate speech for 1 and positive tweets being 0\n",
        "# third columns being the tweets\n",
        "inp_tweets0.head(10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8KLPaF9wSVt",
        "outputId": "600034b9-fcc7-4d49-fddd-9da0a7b3b405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.929854\n",
              "1    0.070146\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To check the number of tweet with hate speech and not.\n",
        "# The data is highly imbalanced. The number of tweets categorized as hate speech are very few \n",
        "inp_tweets0['label'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjroVhD7weZi",
        "outputId": "552bab61-17af-4a63-a27f-6dba77c5f448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['you believe your miscegenation genocide will stop the \"breeding\" of black and white ppl off face of our eah, @user   @user'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Observing one of the observations\n",
        "# Using .sample() on the series to select a random tweet\n",
        "# This returns a series\n",
        "#Now to extract out value, we apply the .values function \n",
        "# This gives an array\n",
        "# THe index is used to extract that value from the array\n",
        "inp_tweets0['tweet'].sample(random_state = 102).values#[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ySIXnAAdKx"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJFVKzRGwolV"
      },
      "source": [
        "# Step 1: Get the tweets into a list, for easy text clean up and manipulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dYlxN7XwkYh"
      },
      "outputs": [],
      "source": [
        "# To extract out tweet column alone, this would give a numpy array\n",
        "tweets0 = inp_tweets0.tweet.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avik7qtNw3l-",
        "outputId": "c28c945e-cf4d-47cb-9af7-05cda7c12ca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31962"
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of tweets in the dataset\n",
        "len(tweets0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUGOpnQGw8UA",
        "outputId": "62bd54a2-a0f7-44d0-ef52-fca102ea83fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              "       \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              "       '  bihday your majesty',\n",
              "       '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              "       ' factsguide: society now    #motivation'], dtype=object)"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Observing the five tweets\n",
        "tweets0[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bBiHtKMBHDi"
      },
      "source": [
        "# Step 2: Coverting the all the tweets  to lower case. This avoides duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCGYHatuxQN2"
      },
      "outputs": [],
      "source": [
        "tweets_lower = [twt.lower() for twt in tweets0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nY7yYCqrxUYE",
        "outputId": "7758995f-965d-46c6-ebc0-bf44ccfd04e7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the next school year is the year for exams.ð\\x9f\\x98¯ can't think about that ð\\x9f\\x98\\xad #school #exams   #hate #imagine #actorslife #revolutionschool #girl\""
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_lower[7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXfYG8-fBW3o"
      },
      "source": [
        "# Step 3: Using regular Expression library to remove the unnecessary characters, which would confuse our machine learning model.\n",
        "\n",
        "1. Remove user handles , begin with @"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5O92sCHAxaOr",
        "outputId": "e769524c-a475-47f0-e484-0826f60c2cec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' you are amazing!!, https//www.google.com'"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking what regular expression to use to remove the '@name_of_the_handle'\n",
        "re.sub(\"@\\w+\",\"\", \"@Jose you are amazing!!, https//www.google.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEZwSWdwxaRL"
      },
      "outputs": [],
      "source": [
        "# Using list comprehension to create a new list containing tweet with no handle names\n",
        "# Applying the RE on all the tweets\n",
        "tweets_nouser = [re.sub(\"@\\w+\",\"\",twt) for twt in tweets_lower]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKmYPGTkxaT2",
        "outputId": "bf27ecdd-0ad3-4cc8-a704-d0fdbe69837a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              " '  bihday your majesty']"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_nouser[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52YVD9LsC83J"
      },
      "source": [
        "2. Removing the URLS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7XcSgWrjyoky",
        "outputId": "5fc0a807-7783-44b8-e7b3-cd99ce2d8013"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@Jose you are amazing '"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking what regular Expression to use, to remove the URLs\n",
        "re.sub(\"\\w+://\\S+\",\"\",\"@Jose you are amazing https://google.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrVj00E2y0Rh"
      },
      "outputs": [],
      "source": [
        "# Now using the regular expression to remove all the urls from the tweets\n",
        "tweets_nourl = [re.sub(\"\\w+://\\S+\",\"\",twt) for twt in tweets_nouser]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FZ8YYX4zGED",
        "outputId": "4e498f18-7fdc-4bd9-855a-428638ad22a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              " '  bihday your majesty',\n",
              " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              " ' factsguide: society now    #motivation']"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# all the URLs in the tweets have been removed\n",
        "tweets_nourl[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GScrT8vEZL5H"
      },
      "source": [
        "3. Removing the non-ASCII Characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_Jv78G70YpWz",
        "outputId": "7389437f-9a6c-493a-b885-29e1cc5bfd10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex'"
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.sub(r'[^\\x00-\\x7f]',\"\",' â #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib6sWteAXhgB"
      },
      "outputs": [],
      "source": [
        "tweets_ASCII = [re.sub(r'[^\\x00-\\x7f]',\"\",twt) for twt in tweets_nouser]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN3sptxDXh1E",
        "outputId": "71c6df52-e202-4e85-914f-e9036f8b9848"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              " '  bihday your majesty',\n",
              " '#model   i love u take with u all the time in ur!!!   ',\n",
              " ' factsguide: society now    #motivation']"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_ASCII[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wq2IWQE_ZmjF",
        "outputId": "f0ae46e6-d226-4db4-c4e6-6ffe6a4e6858"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"happy father's day    \""
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_ASCII[28]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzUqXuUD7PZ"
      },
      "source": [
        "# Step 4: Applying word tokenizing on the tweets, for further cleaning.\n",
        "\n",
        "Breaking a sentence into its parts allows a machine to understand the parts as well as the whole. This will help the program understand each of the words by themselves, as well as how they function in the larger text. This is especially important for larger amounts of text as it allows the machine to count the frequencies of certain words as well as where they frequently appear. This is important for later steps in natural language processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilslnm-0zull"
      },
      "outputs": [],
      "source": [
        "tkn = TweetTokenizer() # Creating an instance of the class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsyxX40wzxuG",
        "outputId": "79bcab11-1226-4f49-8442-c10134baac8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n"
          ]
        }
      ],
      "source": [
        "# This is how tokenization works\n",
        "# We use the tokenize method of the class TweetTokenizer on the first tweet\n",
        "print(tkn.tokenize(tweets_ASCII[0])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uidcg_HPz2zY"
      },
      "outputs": [],
      "source": [
        "# Applying the same to the entire array of tweets\n",
        "tweet_token = [tkn.tokenize(sent) for sent in tweets_ASCII]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQNF39afE3-O",
        "outputId": "a55e06c8-faaf-4089-ac22-6a2fbea0f31a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['thank', 'you', 'for', 'you', 'follow']\n"
          ]
        }
      ],
      "source": [
        "# This is the last tweet in the dataset, each word in the tweet has been considered as a seperate element, \n",
        "# this helps us to apply further operation like stop words removal , removing punctuation, etc easily.\n",
        "print(tweet_token[31961])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlNytK_1GOPL"
      },
      "source": [
        "# Step 5:  Remove punctuations and stop words and other redundant terms like 'rt,'amp', '#'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_m5oIcC09Do"
      },
      "outputs": [],
      "source": [
        "stop_nltk = stopwords.words(\"english\") # Listing all the stop words in a list\n",
        "stop_punct = list(punctuation)         # listing all the punctuation in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQuqoB0V1l13",
        "outputId": "e3b79153-71f1-4195-d028-493af5ff0d6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~']"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_punct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbCrCVo32pkY"
      },
      "outputs": [],
      "source": [
        "stop_punct.extend(['...','```',\"''\",'..']) # adding more expressions into the list of punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYjmrWEx24Ki"
      },
      "outputs": [],
      "source": [
        "stop_context = ['rt','amp']  # Adding few more words for stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJZ7LDs0272i"
      },
      "outputs": [],
      "source": [
        "# Finally creating a list with all the expressions to be removed\n",
        "stop_final = stop_nltk + stop_punct + stop_context "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m29IzpZhL4ZT"
      },
      "source": [
        "**Function to**\n",
        "\n",
        "**Remove stop words from a single tokenize sentence**\n",
        "\n",
        "**remove # tags**\n",
        "\n",
        "**remove terms with length = 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYAw20hx3NJG"
      },
      "outputs": [],
      "source": [
        "def del_stop(sent):\n",
        "    return [re.sub(\"#\",\"\",term) for term in sent if ((term not in stop_final) & (len(term)>1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuVX27Uv3xPH",
        "outputId": "e92f4969-3f84-44e5-9a73-330d1ca80e2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['factsguide', 'society', 'motivation']"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Trying this function on one of the tweets to check if its functioning properly\n",
        "del_stop(tweet_token[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGlEFJvt3092"
      },
      "outputs": [],
      "source": [
        "# Applying the function on all tweets in the list\n",
        "tweets_clean = [del_stop(tweet) for tweet in tweet_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1mTDk354DMS",
        "outputId": "c9d5b122-39e3-4a1b-8905-51865aeadc67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2/2',\n",
              " 'huge',\n",
              " 'fan',\n",
              " 'fare',\n",
              " 'big',\n",
              " 'talking',\n",
              " 'leave',\n",
              " 'chaos',\n",
              " 'pay',\n",
              " 'disputes',\n",
              " 'get',\n",
              " 'allshowandnogo']"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# So the function works fine\n",
        "del_stop(tweets_clean[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuAUSn9xjUo0"
      },
      "source": [
        "# Step 6: Applying lemmitization to the tweets\n",
        "\n",
        "Lemmatization is a text normalization technique used in Natural Language Processing (NLP), that switches any kind of a word to its base root mode. Lemmatization is responsible for grouping different inflected forms of words into the root form, having the same meaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAuE1XpUjA16"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()  # Creating an instance of the object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJkmnSoTjBVc"
      },
      "outputs": [],
      "source": [
        "# Creating a function to apply lemmetization to the tweets\n",
        "def apply_lemmetization(sent):\n",
        "    return [lemmatizer.lemmatize(term) for term in sent]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joa_og0PjBhm",
        "outputId": "b4efba6b-b259-4946-c67a-9aa6ad7d2f6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2/2',\n",
              " 'huge',\n",
              " 'fan',\n",
              " 'fare',\n",
              " 'big',\n",
              " 'talking',\n",
              " 'leave',\n",
              " 'chaos',\n",
              " 'pay',\n",
              " 'disputes',\n",
              " 'get',\n",
              " 'allshowandnogo']"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_clean[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiQz1c2CkRxj"
      },
      "source": [
        "Now to check whether the given function works fine, we apply it to one of the tweets.\n",
        "\n",
        "**Note:** The word 'disputes' have been replaced with 'dispute'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljn5gckaj9Ki",
        "outputId": "6e9979e5-0d55-4131-ef10-47360365a064"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2/2',\n",
              " 'huge',\n",
              " 'fan',\n",
              " 'fare',\n",
              " 'big',\n",
              " 'talking',\n",
              " 'leave',\n",
              " 'chaos',\n",
              " 'pay',\n",
              " 'dispute',\n",
              " 'get',\n",
              " 'allshowandnogo']"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "apply_lemmetization(tweets_clean[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-_xA3A5lIBO"
      },
      "outputs": [],
      "source": [
        "# Applying it to the whole dataset\n",
        "tweets_clean = [apply_lemmetization(sent) for sent in tweets_clean]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JGi0JBJa69N"
      },
      "source": [
        "# To check out the top terms in the tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVvcR49y4TjD"
      },
      "outputs": [],
      "source": [
        "# Creating a new list and adding each of the words in all the tweets to a list term_list\n",
        "# Here, we use .extend(), and not append, check the below cell to understand the reason\n",
        "term_list = []\n",
        "for tweet in tweets_clean:\n",
        "  term_list.extend(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfG3VGEogB8X",
        "outputId": "0e2b4d53-6aa0-48f0-e4b6-b721d9fede6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['father',\n",
              " 'dysfunctional',\n",
              " 'selfish',\n",
              " 'drag',\n",
              " 'kid',\n",
              " 'dysfunction',\n",
              " 'run',\n",
              " 'thanks',\n",
              " 'lyft',\n",
              " 'credit',\n",
              " \"can't\",\n",
              " 'use',\n",
              " 'cause',\n",
              " 'offer',\n",
              " 'wheelchair']"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "term_list[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnBskrh6eRUo",
        "outputId": "5662b5de-7ec8-4002-f63c-9a0ef5fac2f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['a'], ['b'], ['c']]\n",
            "['a', 'b', 'c']\n"
          ]
        }
      ],
      "source": [
        "lis = [['a'],['b'],['c']]\n",
        "ls = []\n",
        "lss = []\n",
        "# Using append\n",
        "for x in lis:\n",
        "  ls.append(x)\n",
        "print(ls)\n",
        "\n",
        "# Using extend\n",
        "for x in lis:\n",
        "  lss.extend(x)\n",
        "print(lss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXJBsNYk4oBb",
        "outputId": "46ccf0ba-3dad-42a8-c7e9-743a4ee8a445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38345\n",
            "<class 'collections.Counter'>\n"
          ]
        }
      ],
      "source": [
        "# This creates a new instance of class counter, It is like dictionary with 'Key' being the words and 'Value' being the count of words in the list\n",
        "res = Counter(term_list) \n",
        "print(len(res))\n",
        "print(type(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ao8YvmPgmT5",
        "outputId": "5455f8ca-1255-489b-e01e-730479665494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('love', 2863),\n",
              " ('day', 2808),\n",
              " ('happy', 1696),\n",
              " ('time', 1252),\n",
              " ('life', 1244),\n",
              " ('like', 1090),\n",
              " ('today', 1037),\n",
              " (\"i'm\", 1017),\n",
              " ('get', 999),\n",
              " ('new', 998)]"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Finding out the top 10 words which have been used in all the tweets combined\n",
        "res.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv7igLv4lj9J"
      },
      "source": [
        "# Step 7: Now converting the tokenize words back as a sentence\n",
        "Joining the tokens back into strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCIB0zcz5TlY",
        "outputId": "6e82276e-9ab0-432e-fa3c-d2b6ae99ccdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['never', 'msg', 'first', 'dun', 'msg', 'first', 'disappointed']"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_clean[30000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4llbAmis5VyM"
      },
      "outputs": [],
      "source": [
        "# Initially it was a list within a list, but now its a simple list, where each element which is of type string is a review (There are no stop words or punctuations)\n",
        "tweets_clean = [\" \".join(tweet) for tweet in tweets_clean]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2G9ZanyI5cZt",
        "outputId": "c59dbaaa-e552-4411-c29b-6a2d671d2a77"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'never msg first dun msg first disappointed'"
            ]
          },
          "execution_count": 270,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_clean[30000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyLrtg3b5xzE",
        "outputId": "1a28410c-b726-47b3-e294-72d089238394"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31962"
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tweets_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6RJQ4ilmsDp"
      },
      "source": [
        "# **Separate X and Y and perform train test split, 70-30**\n",
        "Now after the data cleaning we divide the data into test and train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVtNW94W5zmi",
        "outputId": "f74a1ee5-2740-4c28-f471-7eedf95aba5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31962"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(inp_tweets0['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lgc0eTxB6H55"
      },
      "outputs": [],
      "source": [
        "X = tweets_clean  # List containing all the tweets\n",
        "y = inp_tweets0.label.values # A numpy array containing the true labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1KrRV8i6RY5"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_ccNxiJnQR0"
      },
      "source": [
        "## **Document term matrix using TfIdf**\n",
        "Now to convert the textual data to numerical data, so that we could input it into our model we use vectorization.There are various vectorization techniques like:\n",
        "  One-hot Encoding (OHE)\n",
        "\n",
        "  Count Vectorizer\n",
        "\n",
        "  Bag-of-Words (BOW)\n",
        "\n",
        "  N-grams\n",
        "\n",
        "  Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "Here, we use TF-IDF (Term Frequency and Inverse Document Frequency)- It is a product of two measures:\n",
        "\n",
        "\n",
        "                                              tfidf(t,d,D) = tf(t,d) X idf(t,D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua_uxeMq6xBc"
      },
      "outputs": [],
      "source": [
        "# Create a document term matrix using count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZwbyBqX69Rg"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Using the tfidf for vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnTNfWNS7DZL"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 7000) # Rather than using all the features (unique words) we use only few features based on the max TF value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgG91YFl7PJ_",
        "outputId": "10394e50-8eaf-4db9-99f5-21409e0ecca4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22373, 9589)"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(X_test) # This is the length of the train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt-ojIiS7SgK"
      },
      "outputs": [],
      "source": [
        "# Vectorizing the X_train data and X_test_data\n",
        "X_train_bow = vectorizer.fit_transform(X_train) # Applying fit and transform\n",
        "X_test_bow = vectorizer.transform(X_test)       # Applying transform only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM79IiBN7gJm",
        "outputId": "70f9b726-a8ac-45cf-ddb3-6aa859de94f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((22373, 7000), (9589, 7000))"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_bow.shape, X_test_bow.shape   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CllO1BGNq4bl"
      },
      "source": [
        "# **Model building**\n",
        "\n",
        "Now since we have numeric data, we can fit our model\n",
        "\n",
        "**MODEL 1:** Giving equal weights to all the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNyWyZnk9CNF"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression() #  Creating an instance of the object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3F04fI19Er0",
        "outputId": "0a52c58c-b2fb-433f-e8bf-023859c668b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg.fit(X_train_bow, y_train) #Fiting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAC_P_SD9IL9"
      },
      "outputs": [],
      "source": [
        "y_train_pred = logreg.predict(X_train_bow) # Predicting the y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1aVU5Lc9NZK"
      },
      "outputs": [],
      "source": [
        "y_test_pred = logreg.predict(X_test_bow)   # Predicting the y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV0ZEAWr1i34",
        "outputId": "311c887e-1b68-4296-8375-99d8d6063027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8877   28]\n",
            " [ 466  218]]\n"
          ]
        }
      ],
      "source": [
        "# Printing the confusion matrix\n",
        "print(confusion_matrix(y_test,y_test_pred)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgjFtvb8FZrN",
        "outputId": "7148028f-bca2-48b7-cb73-8b0114f365ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9563759889152103"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Accuracy of the model\n",
        "accuracy_score(y_train,y_train_pred) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfhT6WD99v53",
        "outputId": "719b291a-8e54-4674-e37a-21aed04a80b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9484826363541558"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Accuracy of the model\n",
        "accuracy_score(y_test,y_test_pred) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U_uqVH8936z",
        "outputId": "25fdbdc9-c18f-42ab-fa21-054a30c56312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      8905\n",
            "           1       0.89      0.32      0.47       684\n",
            "\n",
            "    accuracy                           0.95      9589\n",
            "   macro avg       0.92      0.66      0.72      9589\n",
            "weighted avg       0.95      0.95      0.94      9589\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the classification report\n",
        "print(classification_report(y_test,y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6jAXjvvqvNz"
      },
      "source": [
        "**Interpretation:** Even though we have got a good accuracy on the model, but our model fails to predict the tweets with 'hate speech'. Tweets which donot actually belong to hate speech is classified as 'hate speech' (False Positive). This is evident from the low sensitivity and F1 Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8gk4hjd_MoK"
      },
      "source": [
        "# **MODEL 2:** Having unequal weights for the samples\n",
        "\n",
        "Here, new weights are assigned as:\n",
        " \n",
        " weight_class j = total_records / (No. of classes * no. of samples of class j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmY555yh-sNR"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(class_weight = \"balanced\") # Creating an instance of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVBqZP6B-1ks",
        "outputId": "780f4de0-ddd0-4b4f-a850-c5b2e3e44c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced')"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg.fit(X_train_bow, y_train) # Fiting using the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egyslOJ8-5PI"
      },
      "outputs": [],
      "source": [
        "y_train_pred = logreg.predict(X_train_bow) # Predicting the training set using the fitted model\n",
        "y_test_pred = logreg.predict(X_test_bow)   # Predicting the test set using the fitted model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo5IbS3F-JiR",
        "outputId": "be38d142-e619-4834-9a3a-65cd24da1438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[19917,   898],\n",
              "       [   33,  1525]])"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_train,y_train_pred)  # Printing the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH0QMwbn_EWJ",
        "outputId": "436d0b3e-2a74-45c8-8a8d-a50751c0d8ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9583873418853082"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4xiSqqETz1a",
        "outputId": "8790f6b4-b84c-4b1d-ab9f-a018c652140f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.93617686932944"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test,y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpxAL4iN_P42",
        "outputId": "dbd1fdb3-7cc6-4abc-888b-ac341712d53f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97      8905\n",
            "           1       0.54      0.78      0.63       684\n",
            "\n",
            "    accuracy                           0.94      9589\n",
            "   macro avg       0.76      0.86      0.80      9589\n",
            "weighted avg       0.95      0.94      0.94      9589\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BkPOoA1T83m"
      },
      "source": [
        "**Conclusion:** Here, it could be observed that by giving a higher weight to the minority class, there has been an improvement in predicting the True Positives. But, there has been an increase in the False Negatives. The F1 score has improves by 16%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoS2yYqcVPgb"
      },
      "source": [
        "# **MODEL 3:** By changing the inverse of regularization parameters C (which is actually C = (1/lambda), That means lower the C, higher is the regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu_356I6AG7y"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid based on the results of random search\n",
        "param_grid = {\n",
        "    'C': [0.01,0.05,0.1,0.5,0.8]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4HOukF1ASlR"
      },
      "outputs": [],
      "source": [
        "classifier_lr = LogisticRegression(class_weight= \"balanced\") # Creating an instance of the parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xErLVZVwAZdP"
      },
      "outputs": [],
      "source": [
        "# Initiating the grid search model\n",
        "grid_search = GridSearchCV(estimator = classifier_lr,\n",
        "                           param_grid = param_grid,\n",
        "                           cv = StratifiedKFold(4),\n",
        "                           n_jobs = -1, verbose = 1,\n",
        "                           scoring = \"recall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez5aKMoLAvzA",
        "outputId": "b44cfd6a-0e5d-4d93-a2ea-8322d0db5896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
              "             estimator=LogisticRegression(class_weight='balanced'), n_jobs=-1,\n",
              "             param_grid={'C': [0.01, 0.05, 0.1, 0.5, 0.8]}, scoring='recall',\n",
              "             verbose=1)"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.fit(X_train_bow,y_train) # Fiting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5eW5OFZA4TF",
        "outputId": "eeb2831d-a05c-475b-900a-990b398dec80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.5, class_weight='balanced')"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_estimator_ # This gives the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQIQ4yHGBp9I"
      },
      "outputs": [],
      "source": [
        "# Using the best estimator to make predictions on the best set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ve4vgWGB0H7"
      },
      "outputs": [],
      "source": [
        "y_test_pred = grid_search.best_estimator_.predict(X_test_bow) # Predicting the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpTOQU8WB7ZK"
      },
      "outputs": [],
      "source": [
        "y_train_pred = grid_search.best_estimator_.predict(X_train_bow) # Predicting the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvEACNrVW53N",
        "outputId": "d396aa2a-be07-4e83-8c77-4232ecf3e200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9519957091136638"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_train, y_train_pred) # The accuracy of the model in predicting train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHh_-xyaW6Xu",
        "outputId": "b1289319-7d7d-4e15-f833-37517f6b19ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9338825737824591"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test,y_test_pred) # The accuracy of the model in predicting test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZAq3FYeW6g2",
        "outputId": "885ef75a-0270-4612-ff92-2dfdee12b3b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[8414,  491],\n",
              "       [ 143,  541]])"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test,y_test_pred) # The confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Nhi7rUCQCs",
        "outputId": "886eabc4-5c0f-4dcb-e0a3-7a49ce4d7a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96      8905\n",
            "           1       0.52      0.79      0.63       684\n",
            "\n",
            "    accuracy                           0.93      9589\n",
            "   macro avg       0.75      0.87      0.80      9589\n",
            "weighted avg       0.95      0.93      0.94      9589\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWeNiaRBZcNj"
      },
      "source": [
        "**CONCLUSION:** By increasing the l2 regularization, there has been no much improvement in the F! score. Here, C = 0.5, gave the best performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_KnyqnyZzXM"
      },
      "source": [
        "# **MODEL 4:** Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUgcFgtmC2gW"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_estimators = 500,class_weight = \"balanced\") # Creating a instance of the class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBIvjRPSC6Re",
        "outputId": "f0677bce-ea4a-4e35-f594-f2823d5fe906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', n_estimators=500)"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_bow,y_train) # Fiting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuf713jGDCnM"
      },
      "outputs": [],
      "source": [
        "predict_train = model.predict(X_train_bow) # Predicting the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DRO-pQJDaig"
      },
      "outputs": [],
      "source": [
        "predict_test = model.predict(X_test_bow) # Predicting the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHS69tgMFf1_",
        "outputId": "7334b80e-6ae6-4f98-d75a-0017980d9224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9993295490099674"
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_train, predict_train) # The accuracy of the model in predicting the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ISi4AFeDmKg",
        "outputId": "92208c0d-b585-4ceb-b7ca-9ca77af9771a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9589112524767963"
            ]
          },
          "execution_count": 286,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, predict_test) # The accuracy of the model in predicting the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc_TelaRaM4K",
        "outputId": "1721475e-d3d6-4b6b-9c36-2209b1dda80e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[8816,   89],\n",
              "       [ 305,  379]])"
            ]
          },
          "execution_count": 287,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test, predict_test) # The confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw94qmDfFIYJ",
        "outputId": "96fafb50-bbc6-49a2-c289-d9d88be57ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      8905\n",
            "           1       0.81      0.55      0.66       684\n",
            "\n",
            "    accuracy                           0.96      9589\n",
            "   macro avg       0.89      0.77      0.82      9589\n",
            "weighted avg       0.96      0.96      0.96      9589\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predict_test)) # Printing the classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPPUUjJBdP7W"
      },
      "source": [
        "**Conclusion:**  We have observed that Random Forest is best in classifying the tweets as 'hate speech' and 'non- hate speech'. There has been an increase in the F1 score as well as Accuracy. Since the data was heavily imbalanced data, F1 score is considered to be ideal for model performance parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_UX31FLLHDr"
      },
      "source": [
        "# Changing Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnyAkdof5qOn"
      },
      "outputs": [],
      "source": [
        "# Based on the fitted model, predicting the probabilities\n",
        "pred_prob = model.predict_proba(X_test_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fkVc2yR7p_R",
        "outputId": "af1faeed-2adf-4386-cf62-33f3055cdaaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.006"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_prob[0][1] # Predicted probabilities of 1s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B2TwFSB5qRm"
      },
      "outputs": [],
      "source": [
        "# Rather than considering the cut-off value as 0.5, choosing 0.425\n",
        "pred_class = []\n",
        "for x in pred_prob:\n",
        "  if x[1] >=0.425:\n",
        "    pred_class.append(1)\n",
        "  else:\n",
        "    pred_class.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJLDbrYA7NsH",
        "outputId": "d09ac833-70af-49fb-c127-7f22ff458c14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9589"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(pred_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJsIBXO-80JI",
        "outputId": "94cbff7b-8b06-4f34-dbee-1bd2fb63df44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8752  153]\n",
            " [ 263  421]]\n"
          ]
        }
      ],
      "source": [
        "# New confusion Matrix\n",
        "print(confusion_matrix(y_test,pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6stmh0Yh5qaw",
        "outputId": "1e79806a-447d-4cfa-e2dd-5f29916e73b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      8905\n",
            "           1       0.73      0.62      0.67       684\n",
            "\n",
            "    accuracy                           0.96      9589\n",
            "   macro avg       0.85      0.80      0.82      9589\n",
            "weighted avg       0.95      0.96      0.95      9589\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the classification report\n",
        "print(classification_report(y_test,pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaPJAetKz88S",
        "outputId": "4ce06ec2-cef1-4bb4-b403-66914f2b03ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6491373714056502"
            ]
          },
          "execution_count": 295,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matthews_corrcoef(y_test,pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRwhJRrUJyak"
      },
      "source": [
        "**Conclusion:** The model is comparitively performing better. There has been further improvement in the F1 Score. Also, value of Mathew is also near 1. Thus, the prediction is also not random."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}